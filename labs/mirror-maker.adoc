== MirrorMaker

This lab walks through setting up MirrorMaker for replicating messages between different clusters.

=== What does MirrorMaker do?

Often, applications need to communicate between each other across Kafka clusters.
For example, data might be ingested in Kafka in a data center and consumed in another data center, for reasons such as locality.
In this lab we will show how data can be replicated between Kafka clusters using MirrorMaker.

First, we will change the `log-consumer` app.

Let's log back as `admin`.

----
oc login -u admin
----

----
oc project amq-streams
----

----
oc apply -f https://raw.githubusercontent.com/RedHatWorkshops/workshop-amq-streams/master/configurations/applications/timer-producer-team-1.yaml
oc apply -f https://raw.githubusercontent.com/RedHatWorkshops/workshop-amq-streams/master/configurations/applications/log-consumer-team-2.yaml
----

Now the `log-consumer` application consumes data from cluster `team-2`, while `timer-producer` sends data to cluster `team-1`.
If we look at `log-consumer`s output, we will see that no data is received.

We can confirm that pointing the application to the cluster `team-1` will yield data.
----
oc apply -f https://raw.githubusercontent.com/RedHatWorkshops/workshop-amq-streams/master/configurations/applications/log-consumer-team-1.yaml
----

=== Setting up the source and target clusters

We will use the clusters previously created in this workshop in the `team-1` and `team-2` namespaces as source and target clusters.

Make sure that you're still logged in as `admin`.

----
oc login -u admin
oc project amq-streams
----

Now let's deploy MirrorMaker.

----
oc apply -f https://raw.githubusercontent.com/RedHatWorkshops/workshop-amq-streams/master/configurations/clusters/mirror-maker.yaml
----

The notions of producer and consumer are from MirrorMaker's perspective.
Messages will be read by the consumer (in MirrorMaker config) from the source cluster and published by the publisher (in MirrorMaker config) to the target cluster.


Go to the Openshift web console.
Select the `team-2` project.
Navigate to *Applications*->*Pods* and pick production-ready-kafka-0.
Run the following command.

----
./bin/kafka-topics.sh --list --zookeeper localhost:2181
----

This will confirm that the replicated topic `lines` was created automatically.

Now let's deploy `log-consumer` against the cluster in `team-2`:

----
oc apply -f https://raw.githubusercontent.com/RedHatWorkshops/workshop-amq-streams/master/configurations/applications/log-consumer-team-2.yaml
----

Logging the pod again should yield the expected results and data flows between systems.
